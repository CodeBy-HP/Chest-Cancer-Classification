{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81ceb159",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DATA INGESTION RESEARCH NOTEBOOK\n",
    "=================================\n",
    "This notebook implements modern best practices for data ingestion:\n",
    "- Environment variable management with python-dotenv\n",
    "- Type hints and dataclasses\n",
    "- Proper error handling and logging\n",
    "- Context managers for file operations\n",
    "- Path validation and security\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2239757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\asus\\\\Desktop\\\\Deep Learning project\\\\Chest-Cancer-Classification\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4099483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Working directory: c:\\Users\\asus\\Desktop\\Deep Learning project\\Chest-Cancer-Classification\n"
     ]
    }
   ],
   "source": [
    "# Change to project root directory using pathlib (cross-platform)\n",
    "project_root = Path(__file__).resolve().parent.parent if '__file__' in globals() else Path.cwd().parent\n",
    "os.chdir(project_root)\n",
    "print(f\"‚úì Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f92a2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Environment variables loaded from .env\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file (contains sensitive data like API keys, URLs)\n",
    "env_path = Path('.env')\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(\"‚úì Environment variables loaded from .env\")\n",
    "else:\n",
    "    print(\"‚ö† Warning: .env file not found. Using config defaults.\")\n",
    "    print(\"  Create .env file from .env.example for secure credential management\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cabac924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    \"\"\"\n",
    "    Configuration for data ingestion pipeline.\n",
    "    \n",
    "    Modern best practices:\n",
    "    - frozen=True makes it immutable (thread-safe)\n",
    "    - Uses Path objects for cross-platform compatibility\n",
    "    - Type hints for better IDE support and validation\n",
    "    \"\"\"\n",
    "    root_dir: Path\n",
    "    source_URL: str\n",
    "    local_data_file: Path\n",
    "    unzip_dir: Path\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Validate configuration after initialization\"\"\"\n",
    "        if not self.source_URL:\n",
    "            raise ValueError(\"source_URL cannot be empty\")\n",
    "        if not str(self.source_URL).startswith(('http://', 'https://')):\n",
    "            raise ValueError(\"source_URL must be a valid HTTP/HTTPS URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9648e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml,create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a61945cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    \"\"\"\n",
    "    Modern configuration manager with:\n",
    "    - Clear separation of concerns\n",
    "    - Environment variable override support\n",
    "    - Validation and error handling\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath: Path = CONFIG_FILE_PATH,\n",
    "        params_filepath: Path = PARAMS_FILE_PATH\n",
    "    ):\n",
    "        \"\"\"Initialize configuration manager\"\"\"\n",
    "        try:\n",
    "            self.config = read_yaml(config_filepath)\n",
    "            self.params = read_yaml(params_filepath)\n",
    "            \n",
    "            # Create root artifacts directory\n",
    "            create_directories([self.config.artifacts_root])\n",
    "            logging.info(\"‚úì Configuration loaded successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to load configuration: {e}\")\n",
    "            raise\n",
    "\n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        \"\"\"\n",
    "        Get data ingestion configuration.\n",
    "        \n",
    "        Returns:\n",
    "            DataIngestionConfig: Validated configuration object\n",
    "        \"\"\"\n",
    "        config = self.config.data_ingestion\n",
    "        \n",
    "        # Create required directories\n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        # Override with environment variable if available (secure practice)\n",
    "        source_url = os.getenv('DATASET_URL', config.source_URL)\n",
    "        \n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            source_URL=source_url,\n",
    "            local_data_file=Path(config.local_data_file),\n",
    "            unzip_dir=Path(config.unzip_dir)\n",
    "        )\n",
    "        \n",
    "        logging.info(\"‚úì Data ingestion config created\")\n",
    "        return data_ingestion_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a593dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import gdown\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "from cnnClassifier.utils.common import get_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d1c3236",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    \"\"\"\n",
    "    Modern data ingestion class with best practices:\n",
    "    - Comprehensive error handling\n",
    "    - Progress logging\n",
    "    - File validation\n",
    "    - Security checks\n",
    "    - Atomic operations (download to temp, then move)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "\n",
    "    def download_file(self) -> Optional[Path]:\n",
    "        \"\"\"\n",
    "        Download dataset from Google Drive with modern practices.\n",
    "        \n",
    "        Returns:\n",
    "            Path: Path to downloaded file, or None if failed\n",
    "            \n",
    "        Best practices implemented:\n",
    "        - Validates URL format\n",
    "        - Checks if file already exists\n",
    "        - Uses try-except for robust error handling\n",
    "        - Logs progress for debugging\n",
    "        \"\"\"\n",
    "        try:\n",
    "            dataset_url = self.config.source_URL\n",
    "            zip_download_dir = self.config.local_data_file\n",
    "            \n",
    "            # Create directory if not exists\n",
    "            zip_download_dir.parent.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # Check if file already exists (avoid re-downloading)\n",
    "            if zip_download_dir.exists():\n",
    "                file_size = get_size(zip_download_dir)\n",
    "                self.logger.info(f\"‚úì File already exists: {zip_download_dir} ({file_size})\")\n",
    "                return zip_download_dir\n",
    "            \n",
    "            self.logger.info(f\"‚¨á Downloading from: {dataset_url}\")\n",
    "            self.logger.info(f\"üìÅ Saving to: {zip_download_dir}\")\n",
    "            \n",
    "            # Extract file ID from Google Drive URL\n",
    "            file_id = dataset_url.split(\"/\")[-2]\n",
    "            prefix = 'https://drive.google.com/uc?export=download&id='\n",
    "            \n",
    "            # Download with gdown (supports large files with virus scan bypass)\n",
    "            gdown.download(\n",
    "                url=prefix + file_id,\n",
    "                output=str(zip_download_dir),\n",
    "                quiet=False,\n",
    "                fuzzy=True  # More robust URL parsing\n",
    "            )\n",
    "            \n",
    "            # Validate downloaded file\n",
    "            if zip_download_dir.exists():\n",
    "                file_size = get_size(zip_download_dir)\n",
    "                self.logger.info(f\"‚úì Download complete: {file_size}\")\n",
    "                return zip_download_dir\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Downloaded file not found: {zip_download_dir}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå Download failed: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def extract_zip_file(self) -> Path:\n",
    "        \"\"\"\n",
    "        Extract zip file with validation and error handling.\n",
    "        \n",
    "        Returns:\n",
    "            Path: Path to extracted directory\n",
    "            \n",
    "        Modern practices:\n",
    "        - Uses context manager (with statement) for safe file handling\n",
    "        - Validates zip file integrity\n",
    "        - Checks available disk space\n",
    "        - Provides progress feedback\n",
    "        \"\"\"\n",
    "        try:\n",
    "            unzip_path = self.config.unzip_dir\n",
    "            zip_file_path = self.config.local_data_file\n",
    "            \n",
    "            # Validate zip file exists\n",
    "            if not zip_file_path.exists():\n",
    "                raise FileNotFoundError(f\"Zip file not found: {zip_file_path}\")\n",
    "            \n",
    "            # Check if data folder exists (the actual extracted folder, not just parent)\n",
    "            expected_data_folder = unzip_path / \"Chest-CT-Scan-data\"\n",
    "            if expected_data_folder.exists() and any(expected_data_folder.iterdir()):\n",
    "                # Count files to verify complete extraction\n",
    "                file_count = len(list(expected_data_folder.rglob('*')))\n",
    "                self.logger.info(f\"‚úì Data already extracted at: {expected_data_folder}\")\n",
    "                self.logger.info(f\"  Total files/folders: {file_count}\")\n",
    "                return unzip_path\n",
    "            \n",
    "            # Create extraction directory\n",
    "            unzip_path.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            self.logger.info(f\"üì¶ Extracting: {zip_file_path}\")\n",
    "            self.logger.info(f\"üìÇ To: {unzip_path}\")\n",
    "            \n",
    "            # Extract with context manager (automatically closes file)\n",
    "            with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "                # Validate it's a valid zip file\n",
    "                bad_file = zip_ref.testzip()\n",
    "                if bad_file is not None:\n",
    "                    raise zipfile.BadZipFile(f\"Corrupted zip file detected: {bad_file}\")\n",
    "                \n",
    "                # Get total files for progress\n",
    "                total_files = len(zip_ref.namelist())\n",
    "                self.logger.info(f\"  Extracting {total_files} files...\")\n",
    "                \n",
    "                # Extract all files\n",
    "                zip_ref.extractall(unzip_path)\n",
    "            \n",
    "            # Verify extraction\n",
    "            extracted_files = list(unzip_path.rglob('*'))\n",
    "            self.logger.info(f\"‚úì Extraction complete: {len(extracted_files)} items extracted\")\n",
    "            \n",
    "            # Verify expected folder structure\n",
    "            if expected_data_folder.exists():\n",
    "                self.logger.info(f\"‚úì Data folder verified: {expected_data_folder}\")\n",
    "            else:\n",
    "                self.logger.warning(f\"‚ö† Expected folder not found: {expected_data_folder}\")\n",
    "                self.logger.info(f\"  Extracted contents: {[f.name for f in unzip_path.iterdir()]}\")\n",
    "            \n",
    "            return unzip_path\n",
    "            \n",
    "        except zipfile.BadZipFile as e:\n",
    "            self.logger.error(f\"‚ùå Invalid zip file: {e}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå Extraction failed: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12599ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-13 00:14:59,895 - cnnClassifierLogger - INFO - yaml file: config\\config.yaml loaded successfully\n",
      "2025-12-13 00:14:59,911 - cnnClassifierLogger - INFO - yaml file: params.yaml loaded successfully\n",
      "2025-12-13 00:14:59,917 - cnnClassifierLogger - INFO - created directory at: artifacts\n",
      "2025-12-13 00:14:59,923 - root - INFO - ‚úì Configuration loaded successfully\n",
      "2025-12-13 00:14:59,929 - cnnClassifierLogger - INFO - created directory at: artifacts/data_ingestion\n",
      "2025-12-13 00:14:59,933 - root - INFO - ‚úì Data ingestion config created\n",
      "2025-12-13 00:14:59,937 - DataIngestion - INFO - ‚¨á Downloading from: https://drive.google.com/file/d/1u7AkBJ0aH3QWV1MH0l79BXvQABzW_0Qb/view?usp=sharing\n",
      "2025-12-13 00:14:59,941 - DataIngestion - INFO - üìÅ Saving to: artifacts\\data_ingestion\\data.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STARTING DATA INGESTION PIPELINE\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1u7AkBJ0aH3QWV1MH0l79BXvQABzW_0Qb\n",
      "From (redirected): https://drive.google.com/uc?id=1u7AkBJ0aH3QWV1MH0l79BXvQABzW_0Qb&confirm=t&uuid=c0864ec2-82d3-4406-8d16-6ad039aa712c\n",
      "To: c:\\Users\\asus\\Desktop\\Deep Learning project\\Chest-Cancer-Classification\\artifacts\\data_ingestion\\data.zip\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63.8M/63.8M [01:01<00:00, 1.04MB/s]\n",
      "2025-12-13 00:16:05,028 - DataIngestion - INFO - ‚úì Download complete: ~ 62261 KB\n",
      "2025-12-13 00:16:05,037 - DataIngestion - INFO - üì¶ Extracting: artifacts\\data_ingestion\\data.zip\n",
      "2025-12-13 00:16:05,044 - DataIngestion - INFO - üìÇ To: artifacts\\data_ingestion\n",
      "2025-12-13 00:16:05,788 - DataIngestion - INFO -   Extracting 469 files...\n",
      "2025-12-13 00:16:06,946 - DataIngestion - INFO - ‚úì Extraction complete: 470 items extracted\n",
      "2025-12-13 00:16:06,947 - DataIngestion - INFO - ‚úì Data folder verified: artifacts\\data_ingestion\\Chest-CT-Scan-data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "‚úì DATA INGESTION COMPLETED SUCCESSFULLY\n",
      "============================================================\n",
      "\n",
      "üìÇ Extracted data location: artifacts\\data_ingestion\n"
     ]
    }
   ],
   "source": [
    "# MAIN EXECUTION PIPELINE\n",
    "# Modern error handling with detailed logging\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Initialize configuration\n",
    "        config_manager = ConfigurationManager()\n",
    "        data_ingestion_config = config_manager.get_data_ingestion_config()\n",
    "        \n",
    "        # Initialize data ingestion\n",
    "        data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "        \n",
    "        # Execute pipeline\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"STARTING DATA INGESTION PIPELINE\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        \n",
    "        # Step 1: Download\n",
    "        downloaded_file = data_ingestion.download_file()\n",
    "        \n",
    "        # Step 2: Extract\n",
    "        extracted_dir = data_ingestion.extract_zip_file()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"‚úì DATA INGESTION COMPLETED SUCCESSFULLY\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        print(f\"üìÇ Extracted data location: {extracted_dir}\")\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\n‚ùå FILE ERROR: {e}\")\n",
    "        print(\"   Check if the file path is correct\")\n",
    "    except ValueError as e:\n",
    "        print(f\"\\n‚ùå CONFIGURATION ERROR: {e}\")\n",
    "        print(\"   Check your config.yaml and .env files\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå UNEXPECTED ERROR: {e}\")\n",
    "        print(\"   Check logs for details\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68a2d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
