{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MODEL EVALUATION WITH MLFLOW - RESEARCH NOTEBOOK\n",
    "================================================\n",
    "Modern MLflow integration with secure credential management:\n",
    "- Environment variable management with python-dotenv\n",
    "- Secure DagHub authentication\n",
    "- Comprehensive model evaluation metrics\n",
    "- Proper MLflow tracking and logging\n",
    "- Model registry integration\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from typing import Optional, Dict, Any\n",
    "import warnings\n",
    "\n",
    "# Suppress unnecessary warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\asus\\\\Desktop\\\\Deep Learning project\\\\Chest-Cancer-Classification\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Working directory: c:\\Users\\asus\\Desktop\\Deep Learning project\\Chest-Cancer-Classification\n"
     ]
    }
   ],
   "source": [
    "# Navigate to project root\n",
    "project_root = Path(__file__).resolve().parent.parent if '__file__' in globals() else Path.cwd().parent\n",
    "os.chdir(project_root)\n",
    "print(f\"‚úì Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Environment variables loaded from .env\n",
      "‚úì Secure credential management enabled\n",
      "‚úì All required credentials configured\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables for secure credential management\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "env_path = Path('.env')\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(\"‚úì Environment variables loaded from .env\")\n",
    "    print(\"‚úì Secure credential management enabled\")\n",
    "    \n",
    "    # Verify required environment variables\n",
    "    required_vars = ['DAGSHUB_REPO_OWNER', 'DAGSHUB_REPO_NAME', 'MLFLOW_TRACKING_URI']\n",
    "    missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "    \n",
    "    if missing_vars:\n",
    "        print(f\"‚ö† Warning: Missing environment variables: {missing_vars}\")\n",
    "        print(\"  Update your .env file with these values\")\n",
    "    else:\n",
    "        print(\"‚úì All required credentials configured\")\n",
    "else:\n",
    "    print(\"‚ö† Warning: .env file not found\")\n",
    "    print(\"  Create .env from .env.example for secure credential management\")\n",
    "    print(\"  Falling back to hardcoded values (NOT RECOMMENDED for production)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-13 00:27:47,659 - httpx - INFO - HTTP Request: GET https://dagshub.com/api/v1/user \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as CodeBy-HP\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as CodeBy-HP\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-13 00:27:47,700 - dagshub - INFO - Accessing as CodeBy-HP\n",
      "2025-12-13 00:27:49,819 - httpx - INFO - HTTP Request: GET https://dagshub.com/api/v1/repos/CodeBy-HP/chest-cancer-classification \"HTTP/1.1 200 OK\"\n",
      "2025-12-13 00:27:50,987 - httpx - INFO - HTTP Request: GET https://dagshub.com/api/v1/user \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"CodeBy-HP/chest-cancer-classification\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"CodeBy-HP/chest-cancer-classification\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-13 00:27:51,002 - dagshub - INFO - Initialized MLflow to track repo \"CodeBy-HP/chest-cancer-classification\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository CodeBy-HP/chest-cancer-classification initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository CodeBy-HP/chest-cancer-classification initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-13 00:27:51,012 - dagshub - INFO - Repository CodeBy-HP/chest-cancer-classification initialized!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì DagHub initialized: CodeBy-HP/chest-cancer-classification\n",
      "‚úì MLflow tracking enabled\n"
     ]
    }
   ],
   "source": [
    "# Initialize DagHub with credentials from environment variables\n",
    "import dagshub\n",
    "\n",
    "# Get credentials from environment (secure practice)\n",
    "dagshub_owner = os.getenv('DAGSHUB_REPO_OWNER', 'CodeBy-HP')\n",
    "dagshub_repo = os.getenv('DAGSHUB_REPO_NAME', 'chest-cancer-classification')\n",
    "\n",
    "# Initialize DagHub integration\n",
    "try:\n",
    "    dagshub.init(\n",
    "        repo_owner=dagshub_owner,\n",
    "        repo_name=dagshub_repo,\n",
    "        mlflow=True\n",
    "    )\n",
    "    print(f\"‚úì DagHub initialized: {dagshub_owner}/{dagshub_repo}\")\n",
    "    print(\"‚úì MLflow tracking enabled\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö† DagHub initialization warning: {e}\")\n",
    "    print(\"  MLflow will use local tracking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "‚úì Model file found: artifacts\\training\\model.keras\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Verify model file exists\n",
    "model_path = Path(\"artifacts/training/model.keras\")\n",
    "if model_path.exists():\n",
    "    print(f\"‚úì Model file found: {model_path}\")\n",
    "else:\n",
    "    print(f\"‚ùå Model file not found: {model_path}\")\n",
    "    print(\"  Run training notebook first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Model loaded successfully\n",
      "  Model: EfficientNetB0_ChestCancer\n",
      "  Parameters: 4,057,253\n"
     ]
    }
   ],
   "source": [
    "# Load trained model for quick testing\n",
    "try:\n",
    "    model = tf.keras.models.load_model(\"artifacts/training/model.keras\")\n",
    "    print(f\"‚úì Model loaded successfully\")\n",
    "    print(f\"  Model: {model.name}\")\n",
    "    print(f\"  Parameters: {model.count_params():,}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class EvaluationConfig:\n",
    "    \"\"\"\n",
    "    Configuration for model evaluation.\n",
    "    \n",
    "    Modern practices:\n",
    "    - Immutable configuration\n",
    "    - Type hints\n",
    "    - Validation\n",
    "    \"\"\"\n",
    "    path_of_model: Path\n",
    "    training_data: Path\n",
    "    all_params: Dict[str, Any]\n",
    "    mlflow_uri: str\n",
    "    params_image_size: List[int]\n",
    "    params_batch_size: int\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Validate configuration\"\"\"\n",
    "        if not self.path_of_model.exists():\n",
    "            raise FileNotFoundError(f\"Model not found: {self.path_of_model}\")\n",
    "        if not self.training_data.exists():\n",
    "            raise FileNotFoundError(f\"Training data not found: {self.training_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories, save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories, save_json\n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    \"\"\"Modern configuration manager\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath: Path = CONFIG_FILE_PATH,\n",
    "        params_filepath: Path = PARAMS_FILE_PATH\n",
    "    ):\n",
    "        \"\"\"Initialize configuration\"\"\"\n",
    "        try:\n",
    "            self.config = read_yaml(config_filepath)\n",
    "            self.params = read_yaml(params_filepath)\n",
    "            \n",
    "            create_directories([self.config.artifacts_root])\n",
    "            logging.info(\"‚úì Configuration loaded successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to load configuration: {e}\")\n",
    "            raise\n",
    "\n",
    "    def get_evaluation_config(self) -> EvaluationConfig:\n",
    "        \"\"\"Get evaluation configuration with environment variable overrides\"\"\"\n",
    "        \n",
    "        # Get MLflow URI from environment (secure practice)\n",
    "        mlflow_uri = os.getenv(\n",
    "            'MLFLOW_TRACKING_URI',\n",
    "            f\"https://dagshub.com/{os.getenv('DAGSHUB_REPO_OWNER', 'CodeBy-HP')}/\"\n",
    "            f\"{os.getenv('DAGSHUB_REPO_NAME', 'chest-cancer-classification')}.mlflow\"\n",
    "        )\n",
    "        \n",
    "        eval_config = EvaluationConfig(\n",
    "            path_of_model=Path(\"artifacts/training/model.keras\"),\n",
    "            training_data=Path(\"artifacts/data_ingestion/Chest-CT-Scan-data\"),\n",
    "            mlflow_uri=mlflow_uri,\n",
    "            all_params=self.params,\n",
    "            params_image_size=self.params.IMAGE_SIZE,\n",
    "            params_batch_size=self.params.BATCH_SIZE\n",
    "        )\n",
    "        \n",
    "        logging.info(\"‚úì Evaluation config created\")\n",
    "        logging.info(f\"  MLflow URI: {mlflow_uri}\")\n",
    "        \n",
    "        return eval_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow version: 3.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from urllib.parse import urlparse\n",
    "import dagshub\n",
    "import logging\n",
    "\n",
    "print(f\"MLflow version: {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation:\n",
    "    \"\"\"\n",
    "    Modern model evaluation with MLflow tracking.\n",
    "    \n",
    "    Best practices:\n",
    "    - Secure credential management from environment\n",
    "    - Comprehensive metrics tracking\n",
    "    - Model registry integration\n",
    "    - Proper error handling\n",
    "    - Production-ready logging\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: EvaluationConfig):\n",
    "        self.config = config\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.model = None\n",
    "        self.valid_generator = None\n",
    "        self.score = None\n",
    "\n",
    "    def _valid_generator(self) -> tf.data.Dataset:\n",
    "        \"\"\"\n",
    "        Create validation dataset using modern tf.data API.\n",
    "        \n",
    "        Returns:\n",
    "            tf.data.Dataset: Validation dataset\n",
    "        \"\"\"\n",
    "        try:\n",
    "            image_size = tuple(self.config.params_image_size[:-1])\n",
    "            batch_size = self.config.params_batch_size\n",
    "            \n",
    "            self.logger.info(f\"Loading validation data from: {self.config.training_data}\")\n",
    "            \n",
    "            # Create validation dataset (30% for thorough evaluation)\n",
    "            self.valid_generator = tf.keras.utils.image_dataset_from_directory(\n",
    "                directory=str(self.config.training_data),\n",
    "                validation_split=0.30,\n",
    "                subset=\"validation\",\n",
    "                seed=123,\n",
    "                image_size=image_size,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,  # Don't shuffle for consistent evaluation\n",
    "                label_mode='categorical'\n",
    "            )\n",
    "            \n",
    "            # Get class names BEFORE transformations (important!)\n",
    "            class_names = self.valid_generator.class_names\n",
    "            self.logger.info(f\"‚úì Classes detected: {class_names}\")\n",
    "            \n",
    "            # Normalize pixel values\n",
    "            normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "            self.valid_generator = self.valid_generator.map(\n",
    "                lambda x, y: (normalization_layer(x), y),\n",
    "                num_parallel_calls=tf.data.AUTOTUNE\n",
    "            )\n",
    "            \n",
    "            # Optimize performance\n",
    "            self.valid_generator = self.valid_generator.cache().prefetch(\n",
    "                buffer_size=tf.data.AUTOTUNE\n",
    "            )\n",
    "            \n",
    "            self.logger.info(f\"‚úì Validation data loaded and preprocessed\")\n",
    "            \n",
    "            return self.valid_generator\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to create validation generator: {e}\")\n",
    "            raise\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(path: Path) -> tf.keras.Model:\n",
    "        \"\"\"\n",
    "        Load model from .keras file.\n",
    "        \n",
    "        Args:\n",
    "            path: Path to model file\n",
    "            \n",
    "        Returns:\n",
    "            tf.keras.Model: Loaded model\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not path.exists():\n",
    "                raise FileNotFoundError(f\"Model file not found: {path}\")\n",
    "            \n",
    "            model = tf.keras.models.load_model(path)\n",
    "            logging.info(f\"‚úì Model loaded from: {path}\")\n",
    "            \n",
    "            return model\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to load model: {e}\")\n",
    "            raise\n",
    "\n",
    "    def evaluation(self) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Evaluate model and return metrics.\n",
    "        \n",
    "        Returns:\n",
    "            Dict: Evaluation metrics\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.logger.info(\"Starting model evaluation...\")\n",
    "            \n",
    "            # Load model\n",
    "            self.model = self.load_model(self.config.path_of_model)\n",
    "            \n",
    "            # Create validation data\n",
    "            self._valid_generator()\n",
    "            \n",
    "            # Evaluate model\n",
    "            self.logger.info(\"Evaluating model on validation data...\")\n",
    "            results = self.model.evaluate(self.valid_generator, verbose=1)\n",
    "            \n",
    "            # Extract metrics (based on model compilation)\n",
    "            metric_names = self.model.metrics_names\n",
    "            self.score = dict(zip(metric_names, results))\n",
    "            \n",
    "            self.logger.info(\"‚úì Evaluation completed\")\n",
    "            self.logger.info(f\"  Metrics: {self.score}\")\n",
    "            \n",
    "            # Save scores locally\n",
    "            self.save_score()\n",
    "            \n",
    "            return self.score\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Evaluation failed: {e}\")\n",
    "            raise\n",
    "\n",
    "    def save_score(self) -> None:\n",
    "        \"\"\"Save evaluation scores to JSON file\"\"\"\n",
    "        try:\n",
    "            save_json(path=Path(\"scores.json\"), data=self.score)\n",
    "            self.logger.info(\"‚úì Scores saved to scores.json\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to save scores: {e}\")\n",
    "            raise\n",
    "\n",
    "    def log_into_mlflow(self) -> None:\n",
    "        \"\"\"\n",
    "        Log experiment to MLflow with secure credential management.\n",
    "        \n",
    "        Modern best practices:\n",
    "        - Credentials from environment variables\n",
    "        - Comprehensive parameter and metric logging\n",
    "        - Model registry integration\n",
    "        - Proper error handling\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Set MLflow tracking URI from config\n",
    "            mlflow.set_tracking_uri(self.config.mlflow_uri)\n",
    "            self.logger.info(f\"‚úì MLflow tracking URI set: {self.config.mlflow_uri}\")\n",
    "            \n",
    "            # Get tracking URL type\n",
    "            tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "            \n",
    "            # Start MLflow run\n",
    "            with mlflow.start_run():\n",
    "                self.logger.info(\"‚úì MLflow run started\")\n",
    "                \n",
    "                # Log all parameters from params.yaml\n",
    "                self.logger.info(\"Logging parameters...\")\n",
    "                mlflow.log_params(self.config.all_params)\n",
    "                \n",
    "                # Log all evaluation metrics\n",
    "                self.logger.info(\"Logging metrics...\")\n",
    "                mlflow.log_metrics(self.score)\n",
    "                \n",
    "                # Log model to MLflow\n",
    "                self.logger.info(\"Logging model...\")\n",
    "                \n",
    "                # Model registry works with remote tracking (DagHub)\n",
    "                if tracking_url_type_store != \"file\":\n",
    "                    self.logger.info(\"Remote tracking detected - registering model...\")\n",
    "                    \n",
    "                    # Register model with versioning\n",
    "                    # Note: MLflow automatically handles .keras format in TF 3.0+\n",
    "                    mlflow.keras.log_model(\n",
    "                        self.model,\n",
    "                        artifact_path=\"model\",\n",
    "                        registered_model_name=\"EfficientNetB0_ChestCancer\"\n",
    "                    )\n",
    "                    \n",
    "                    self.logger.info(\"‚úì Model registered in MLflow Model Registry\")\n",
    "                else:\n",
    "                    # Local tracking (file store)\n",
    "                    self.logger.info(\"Local tracking detected - logging model...\")\n",
    "                    \n",
    "                    mlflow.keras.log_model(\n",
    "                        self.model,\n",
    "                        artifact_path=\"model\"\n",
    "                    )\n",
    "                    \n",
    "                    self.logger.info(\"‚úì Model logged to MLflow (local)\")\n",
    "                \n",
    "                # Get run ID for reference\n",
    "                run_id = mlflow.active_run().info.run_id\n",
    "                self.logger.info(f\"‚úì MLflow run completed: {run_id}\")\n",
    "                \n",
    "                print(\"\\n\" + \"=\"*60)\n",
    "                print(\"‚úì MLFLOW LOGGING SUCCESSFUL\")\n",
    "                print(\"=\"*60)\n",
    "                print(f\"Run ID: {run_id}\")\n",
    "                print(f\"Tracking URI: {self.config.mlflow_uri}\")\n",
    "                print(\"=\"*60 + \"\\n\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"MLflow logging failed: {e}\")\n",
    "            self.logger.error(\"Check your DagHub credentials in .env file\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-13 00:32:37,408 - cnnClassifierLogger - INFO - yaml file: config\\config.yaml loaded successfully\n",
      "2025-12-13 00:32:37,419 - cnnClassifierLogger - INFO - yaml file: params.yaml loaded successfully\n",
      "2025-12-13 00:32:37,425 - cnnClassifierLogger - INFO - created directory at: artifacts\n",
      "2025-12-13 00:32:37,427 - root - INFO - ‚úì Configuration loaded successfully\n",
      "2025-12-13 00:32:37,431 - root - INFO - ‚úì Evaluation config created\n",
      "2025-12-13 00:32:37,434 - root - INFO -   MLflow URI: https://dagshub.com/CodeBy-HP/chest-cancer-classification.mlflow\n",
      "2025-12-13 00:32:37,436 - Evaluation - INFO - Starting model evaluation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL EVALUATION & MLFLOW TRACKING\n",
      "============================================================\n",
      "\n",
      "Step 1/3: Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-13 00:32:39,444 - root - INFO - ‚úì Model loaded from: artifacts\\training\\model.keras\n",
      "2025-12-13 00:32:39,445 - Evaluation - INFO - Loading validation data from: artifacts\\data_ingestion\\Chest-CT-Scan-data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 466 files belonging to 2 classes.\n",
      "Using 139 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-13 00:32:39,516 - Evaluation - INFO - ‚úì Classes detected: ['adenocarcinoma', 'normal']\n",
      "2025-12-13 00:32:39,543 - Evaluation - INFO - ‚úì Validation data loaded and preprocessed\n",
      "2025-12-13 00:32:39,545 - Evaluation - INFO - Evaluating model on validation data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 394ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.5527 - precision: 1.0000 - recall: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-13 00:32:52,135 - Evaluation - INFO - ‚úì Evaluation completed\n",
      "2025-12-13 00:32:52,136 - Evaluation - INFO -   Metrics: {'loss': 0.5526924729347229, 'compile_metrics': 1.0}\n",
      "2025-12-13 00:32:52,138 - cnnClassifierLogger - INFO - json file saved at: scores.json\n",
      "2025-12-13 00:32:52,139 - Evaluation - INFO - ‚úì Scores saved to scores.json\n",
      "2025-12-13 00:32:52,144 - cnnClassifierLogger - INFO - json file saved at: scores.json\n",
      "2025-12-13 00:32:52,146 - Evaluation - INFO - ‚úì Scores saved to scores.json\n",
      "2025-12-13 00:32:52,149 - Evaluation - INFO - ‚úì MLflow tracking URI set: https://dagshub.com/CodeBy-HP/chest-cancer-classification.mlflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "EVALUATION RESULTS\n",
      "------------------------------------------------------------\n",
      "loss.................................... 0.5527\n",
      "compile_metrics......................... 1.0000\n",
      "------------------------------------------------------------\n",
      "\n",
      "Step 2/3: Saving scores...\n",
      "‚úì Scores saved to scores.json\n",
      "\n",
      "Step 3/3: Logging to MLflow...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-13 00:32:53,633 - Evaluation - INFO - ‚úì MLflow run started\n",
      "2025-12-13 00:32:53,636 - Evaluation - INFO - Logging parameters...\n",
      "2025-12-13 00:32:54,141 - Evaluation - INFO - Logging metrics...\n",
      "2025-12-13 00:32:54,608 - Evaluation - INFO - Logging model...\n",
      "2025-12-13 00:32:54,610 - Evaluation - INFO - Remote tracking detected - registering model...\n",
      "2025/12/13 00:32:54 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/13 00:32:57 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "Successfully registered model 'EfficientNetB0_ChestCancer'.\n",
      "2025/12/13 00:34:07 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: EfficientNetB0_ChestCancer, version 1\n",
      "Created version '1' of model 'EfficientNetB0_ChestCancer'.\n",
      "2025-12-13 00:34:09,317 - Evaluation - INFO - ‚úì Model registered in MLflow Model Registry\n",
      "2025-12-13 00:34:09,319 - Evaluation - INFO - ‚úì MLflow run completed: 120ba9f82978450f9a07632704569ede\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "‚úì MLFLOW LOGGING SUCCESSFUL\n",
      "============================================================\n",
      "Run ID: 120ba9f82978450f9a07632704569ede\n",
      "Tracking URI: https://dagshub.com/CodeBy-HP/chest-cancer-classification.mlflow\n",
      "============================================================\n",
      "\n",
      "üèÉ View run burly-bug-834 at: https://dagshub.com/CodeBy-HP/chest-cancer-classification.mlflow/#/experiments/0/runs/120ba9f82978450f9a07632704569ede\n",
      "üß™ View experiment at: https://dagshub.com/CodeBy-HP/chest-cancer-classification.mlflow/#/experiments/0\n",
      "\n",
      "============================================================\n",
      "‚úì EVALUATION COMPLETED SUCCESSFULLY\n",
      "============================================================\n",
      "\n",
      "üìä View results:\n",
      "  - Local: scores.json\n",
      "  - MLflow UI: https://dagshub.com/CodeBy-HP/chest-cancer-classification.mlflow\n",
      "\n",
      "‚ú® All done!\n"
     ]
    }
   ],
   "source": [
    "# MAIN EXECUTION PIPELINE\n",
    "# Production-ready evaluation with MLflow tracking\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"MODEL EVALUATION & MLFLOW TRACKING\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        \n",
    "        # Initialize configuration\n",
    "        config_manager = ConfigurationManager()\n",
    "        eval_config = config_manager.get_evaluation_config()\n",
    "        \n",
    "        # Initialize evaluation\n",
    "        evaluation = Evaluation(eval_config)\n",
    "        \n",
    "        # Step 1: Evaluate model\n",
    "        print(\"Step 1/3: Evaluating model...\")\n",
    "        metrics = evaluation.evaluation()\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\n\" + \"-\"*60)\n",
    "        print(\"EVALUATION RESULTS\")\n",
    "        print(\"-\"*60)\n",
    "        for metric_name, value in metrics.items():\n",
    "            print(f\"{metric_name:.<40} {value:.4f}\")\n",
    "        print(\"-\"*60 + \"\\n\")\n",
    "        \n",
    "        # Step 2: Save scores\n",
    "        print(\"Step 2/3: Saving scores...\")\n",
    "        evaluation.save_score()\n",
    "        print(\"‚úì Scores saved to scores.json\")\n",
    "        \n",
    "        # Step 3: Log to MLflow\n",
    "        print(\"\\nStep 3/3: Logging to MLflow...\")\n",
    "        evaluation.log_into_mlflow()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"‚úì EVALUATION COMPLETED SUCCESSFULLY\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        print(\"üìä View results:\")\n",
    "        print(f\"  - Local: scores.json\")\n",
    "        print(f\"  - MLflow UI: {eval_config.mlflow_uri}\")\n",
    "        print(\"\\n‚ú® All done!\")\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\n‚ùå FILE ERROR: {e}\")\n",
    "        print(\"   Ensure training completed successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR: {e}\")\n",
    "        print(\"\\nTroubleshooting:\")\n",
    "        print(\"1. Check .env file has correct DagHub credentials\")\n",
    "        print(\"2. Ensure model training completed successfully\")\n",
    "        print(\"3. Verify internet connection for DagHub/MLflow\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
